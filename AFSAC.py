#!/usr/bin/env python3
import pygame
import sys
import time
import random
import threading
import requests
import subprocess
import os
import json
import re
import math
from datetime import datetime

# === –ü–û–ü–´–¢–ö–ê –ò–ú–ü–û–†–¢–ê VOSK ===
try:
    from vosk import Model, KaldiRecognizer
    import pyaudio
    VOSK_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Vosk or PyAudio not installed. Install them:")
    print("   pip install vosk pyaudio")
    print("   sudo apt install portaudio19-dev")
    VOSK_AVAILABLE = False

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===
pygame.init()
WIDTH, HEIGHT = 1000, 700
screen = pygame.display.set_mode((WIDTH, HEIGHT))
pygame.display.set_caption("Cute Robot Kitty <3")
clock = pygame.time.Clock()

# === –¶–í–ï–¢–ê ===
BACKGROUND = (0, 0, 0)
TEXT_COLOR = (255, 255, 255)
LISTENING_COLOR = (100, 200, 255)
BLUSH_COLOR = (255, 150, 150)
IDLE_COLOR = (150, 150, 150)
ROBOT_COLOR = (255, 180, 255)

# === –®–†–ò–§–¢–´ ===
face_font = pygame.font.SysFont("monospace", 140, bold=True)
status_font = pygame.font.SysFont("dejavusans", 36, bold=True)

# === –õ–ò–¶–ê ===
IDLE_FACE = "(‚Ä¢œâ‚Ä¢)"
BLINK_FACE = "(^œâ^)"
SPEAKING_FACE = "(^‚ñΩ^)"
LISTENING_FACE = "(‚Ä¢‚ó°‚Ä¢)"
BLUSH_FACE = "(\\>\‚ñΩ\<\\)"

# === –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –î–õ–Ø –ü–û–ö–†–ê–°–ù–ï–ù–ò–Ø ===
COMPLIMENT_WORDS = [
    "–º–∏–ª—ã–π", "–∫—Ä–∞—Å–∏–≤—ã–π", "—É–º–Ω—ã–π", "–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "—Ö–æ—Ä–æ—à–∏–π",
    "–ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π", "–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π", "—á—É–¥–µ—Å–Ω—ã–π", "—Å–∏–º–ø–∞—Ç–∏—á–Ω—ã–π",
    "–∫–æ—Ç–∏–∫", "–∫–æ—Ç—ë–Ω–æ–∫", "–∫–æ—à–µ—á–∫–∞", "—Ä–æ–±–æ—Ç–∏–∫",
    "cute", "beautiful", "smart", "love", "adore", "good",
    "wonderful", "amazing", "fantastic", "sweet",
    "kitty", "kitten", "robot"
]

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
PIPER_PATH = "/home/user/piper/piper"
VOICE_MODEL = "/home/user/piper/voices/en_US/amy/medium/en_US-amy-medium.onnx"
VOICE_CONFIG = "/home/user/piper/voices/en_US/amy/medium/en_US-amy-medium.onnx.json"
OLLAMA_HOST = "http://localhost:11434"
OLLAMA_MODEL = "gemma3:27b-cloud"
VOSK_MODEL_PATH = "/home/kostik/vosk-en/vosk-model-small-en-us-0.15"

# === –ü–ê–ú–Ø–¢–¨ –†–û–ë–û–¢–ê ===
conversation_memory = [
    {"role": "system", "content": "You are a cute catgirl robot named Mika. Always respond in English, be friendly, playful, and remember our conversation. Use emojis like ^‚ñΩ^ and ‚Ä¢œâ‚Ä¢ to express emotions!"}
]
MAX_MEMORY_MESSAGES = 12

# === –°–û–°–¢–û–Ø–ù–ò–Ø ===
is_blinking = False
blink_start = 0
blink_duration = 0.15
last_blink = time.time()
is_speaking = False
mic_active = False
wake_word_active = True
stop_listening = False
blush_until = 0
audio_stream = None
pyaudio_instance = None
wake_stream = None
wake_pyaudio = None
speech_start_time = 0
mic_was_active_before_speaking = False

# === –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –¢–ï–†–ú–ò–ù–ê–õ–ê ===
def timestamp():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ [HH:MM:SS]"""
    return datetime.now().strftime("[%H:%M:%S]")

def print_user(text):
    """–í—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª —Å —Ü–≤–µ—Ç–æ–º"""
    print(f"{timestamp()} \033[1;32m[—Ç—ã]\033[0m {text}")

def print_robot(text):
    """–í—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è —Ä–æ–±–æ—Ç–∞ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª —Å —Ü–≤–µ—Ç–æ–º"""
    print(f"{timestamp()} \033[1;35m[–º–∏–∫–∞]\033[0m {text}")

def print_system(text, color="36"):
    """–í—ã–≤–æ–¥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    print(f"{timestamp()} \033[1;{color}m[—Å–∏—Å—Ç–µ–º–∞]\033[0m {text}")

# === –ü–†–û–í–ï–†–ö–ê –ö–û–ú–ü–õ–ò–ú–ï–ù–¢–û–í ===
def is_compliment(text):
    text_lower = text.lower()
    for word in COMPLIMENT_WORDS:
        if word in text_lower:
            return True
    return False

# === TTS (PIPER) –° –õ–û–ì–ò–†–û–í–ê–ù–ò–ï–ú –í –¢–ï–†–ú–ò–ù–ê–õ ===
def speak_text(text):
    global is_speaking, blush_until, speech_start_time, mic_active, stop_listening, mic_was_active_before_speaking
    
    # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Ä–æ–±–æ—Ç–∞ –í –¢–ï–†–ú–ò–ù–ê–õ
    print_robot(text)
    
    mic_was_active_before_speaking = mic_active
    
    if mic_active:
        stop_listening = True
        mic_active = False
        print_system("–º–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á—ë–Ω (—Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç)", "33")
    
    if is_compliment(text):
        blush_until = time.time() + 2.5
    
    is_speaking = True
    speech_start_time = time.time()
    
    def tts_thread():
        try:
            clean_text = text.replace("*", "").replace("#", "").replace("```", "").strip()
            if not clean_text:
                clean_text = "hi"
            
            subprocess.run(
                [
                    PIPER_PATH,
                    "--model", VOICE_MODEL,
                    "--config", VOICE_CONFIG,
                    "--output_file", "/tmp/robot_response.wav"
                ],
                input=clean_text.encode('utf-8'),
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            subprocess.run(["aplay", "-q", "/tmp/robot_response.wav"], check=False)
        except Exception as e:
            print_system(f"–æ—à–∏–±–∫–∞ TTS: {e}", "31")
        finally:
            global is_speaking, mic_active, stop_listening
            is_speaking = False
            
            if mic_was_active_before_speaking and not stop_listening:
                mic_active = True
                stop_listening = False
                threading.Thread(target=listen_main_microphone, daemon=True).start()
                print_system("–º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á—ë–Ω (—Ä–æ–±–æ—Ç –∑–∞–∫–æ–Ω—á–∏–ª –≥–æ–≤–æ—Ä–∏—Ç—å)", "32")
    
    threading.Thread(target=tts_thread, daemon=True).start()

# === OLLAMA –° –ü–ê–ú–Ø–¢–¨–Æ ===
def ask_ollama(prompt):
    global conversation_memory
    
    try:
        conversation_memory.append({"role": "user", "content": prompt})
        
        if len(conversation_memory) > MAX_MEMORY_MESSAGES + 1:
            conversation_memory = [conversation_memory[0]] + conversation_memory[-MAX_MEMORY_MESSAGES:]
        
        response = requests.post(
            f"{OLLAMA_HOST}/api/chat",
            json={
                "model": OLLAMA_MODEL,
                "messages": conversation_memory,
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            answer = response.json()["message"]["content"].strip()
            conversation_memory.append({"role": "assistant", "content": answer})
            
            if len(conversation_memory) > MAX_MEMORY_MESSAGES + 1:
                conversation_memory = [conversation_memory[0]] + conversation_memory[-MAX_MEMORY_MESSAGES:]
            
            return answer
        else:
            fallback = "Meow? I didn't understand..."
            conversation_memory.append({"role": "assistant", "content": fallback})
            return fallback
            
    except Exception as e:
        print_system(f"–æ—à–∏–±–∫–∞ Ollama: {e}", "31")
        fallback = "Meow? My brain is fuzzy..."
        conversation_memory.append({"role": "assistant", "content": fallback})
        return fallback

# === –û–°–ù–û–í–ù–û–ô –ú–ò–ö–†–û–§–û–ù ===
def listen_main_microphone():
    global mic_active, stop_listening, audio_stream, pyaudio_instance
    
    if not VOSK_AVAILABLE or not os.path.exists(VOSK_MODEL_PATH):
        mic_active = False
        return
    
    try:
        model = Model(VOSK_MODEL_PATH)
        recognizer = KaldiRecognizer(model, 16000)
        
        pyaudio_instance = pyaudio.PyAudio()
        audio_stream = pyaudio_instance.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=16000,
            input=True,
            frames_per_buffer=8000
        )
        audio_stream.start_stream()
        
        recognizer.Reset()
        print_system("–º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á—ë–Ω", "32")
        
        while mic_active and not stop_listening:
            try:
                data = audio_stream.read(4000, exception_on_overflow=False)
                
                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    text = result.get("text", "").strip()
                    if text and mic_active:
                        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –í –¢–ï–†–ú–ò–ù–ê–õ
                        print_user(text)
                        
                        if is_compliment(text):
                            global blush_until
                            blush_until = time.time() + 2.0
                            speak_text("Eeek... thank you... *blushes*")
                        
                        stop_listening = True
                        mic_active = False
                        
                        def get_response():
                            answer = ask_ollama(text)
                            speak_text(answer)
                        
                        threading.Thread(target=get_response, daemon=True).start()
                        recognizer.Reset()
                
            except Exception as e:
                print_system(f"–æ—à–∏–±–∫–∞ –∞—É–¥–∏–æ: {e}", "31")
                break
        
        if audio_stream:
            audio_stream.stop_stream()
            audio_stream.close()
        if pyaudio_instance:
            pyaudio_instance.terminate()
        
        print_system("–º–∏–∫—Ä–æ—Ñ–æ–Ω –≤—ã–∫–ª—é—á—ë–Ω", "33")
        
    except Exception as e:
        print_system(f"–æ—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}", "31")
    finally:
        mic_active = False
        stop_listening = False

# === WAKE WORD –ú–ò–ö–†–û–§–û–ù ===
def listen_wake_word():
    global wake_word_active, wake_stream, wake_pyaudio, mic_active
    
    if not VOSK_AVAILABLE or not os.path.exists(VOSK_MODEL_PATH):
        return
    
    try:
        model = Model(VOSK_MODEL_PATH)
        recognizer = KaldiRecognizer(model, 16000)
        
        wake_pyaudio = pyaudio.PyAudio()
        wake_stream = wake_pyaudio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=16000,
            input=True,
            frames_per_buffer=8000
        )
        wake_stream.start_stream()
        
        print_system("—Ñ–æ–Ω–æ–≤–æ–µ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ '–∫–æ—Ç–∏–∫/kitty' –∑–∞–ø—É—â–µ–Ω–æ", "34")
        
        while wake_word_active:
            try:
                data = wake_stream.read(4000, exception_on_overflow=False)
                
                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    text = result.get("text", "").strip().lower()
                    
                    if not is_speaking and ("–∫–æ—Ç–∏–∫" in text or "–∫–æ—Ç—ë–Ω–æ–∫" in text or "kitty" in text or "robot" in text):
                        print_system(f"—É—Å–ª—ã—à–∞–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ: '{text}'", "35")
                        
                        if not mic_active:
                            mic_active = True
                            stop_listening = False
                            threading.Thread(target=listen_main_microphone, daemon=True).start()
                            
                            global blush_until
                            blush_until = time.time() + 3.0
                            speak_text("Meow! I'm here!")
                        
                        recognizer.Reset()
            
            except Exception as e:
                print_system(f"–æ—à–∏–±–∫–∞ wake-word: {e}", "31")
                break
        
        if wake_stream:
            wake_stream.stop_stream()
            wake_stream.close()
        if wake_pyaudio:
            wake_pyaudio.terminate()
            
    except Exception as e:
        print_system(f"–æ—à–∏–±–∫–∞ wake-word –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}", "31")

# === –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –ú–ò–ö–†–û–§–û–ù–ê ===
def toggle_microphone():
    global mic_active, stop_listening
    
    if is_speaking:
        print_system("–Ω–µ–ª—å–∑—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–æ –≤—Ä–µ–º—è —Ä–µ—á–∏", "33")
        return
    
    if mic_active:
        stop_listening = True
        mic_active = False
        print_system("–º–∏–∫—Ä–æ—Ñ–æ–Ω –≤—ã–∫–ª—é—á–µ–Ω –≤—Ä—É—á–Ω—É—é", "33")
    else:
        mic_active = True
        stop_listening = False
        threading.Thread(target=listen_main_microphone, daemon=True).start()
        print_system("–º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á—ë–Ω –≤—Ä—É—á–Ω—É—é", "32")

# === –°–ë–†–û–° –ü–ê–ú–Ø–¢–ò ===
def reset_memory():
    global conversation_memory
    conversation_memory = [
        {"role": "system", "content": "You are a cute catgirl robot named Mika. Always respond in English, be friendly, playful, and remember our conversation. Use emojis like ^‚ñΩ^ and ‚Ä¢œâ‚Ä¢ to express emotions!"}
    ]
    print_system("–ø–∞–º—è—Ç—å —Å–±—Ä–æ—à–µ–Ω–∞ ‚Äî –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä!", "36")
    speak_text("Memory reset! Let's start fresh! ^‚ñΩ^")

# === –ü–†–ò–í–ï–¢–°–¢–í–ò–ï ===
print("\033[1;35m" + "="*60 + "\033[0m")
print_system("–†–û–ë–û–¢-–ö–û–¢–ò–ö –ú–ò–ö–ê –ó–ê–ü–£–©–ï–ù", "35")
print_system("–ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–∞–º—è—Ç—å—é –∏ —ç–º–æ—Ü–∏—è–º–∏", "35")
print_system("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:", "34")
print_system("  SPACE ‚Äî –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω", "34")
print_system("  R     ‚Äî —Å–±—Ä–æ—Å–∏—Ç—å –ø–∞–º—è—Ç—å", "34")
print_system("  ESC   ‚Äî –≤—ã–π—Ç–∏", "34")
print_system("–°–∫–∞–∂–∏ '–∫–æ—Ç–∏–∫' –∏–ª–∏ 'kitty' –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏!", "35")
print("\033[1;35m" + "="*60 + "\033[0m\n")

# === –ó–ê–ü–£–°–ö WAKE WORD –í –§–û–ù–ï ===
if VOSK_AVAILABLE and os.path.exists(VOSK_MODEL_PATH):
    threading.Thread(target=listen_wake_word, daemon=True).start()
else:
    print_system("‚ö†Ô∏è  Vosk –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –º–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á—ë–Ω", "31")

# –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
speak_text("Hello! I'm Mika, your catgirl robot friend! Say 'kitty' or press SPACE!")

# === –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ===
running = True
while running:
    current_time = time.time()
    
    for event in pygame.event.get():
        if event.type == pygame.QUIT:
            running = False
        
        if event.type == pygame.KEYDOWN:
            if event.key == pygame.K_SPACE and not is_speaking:
                toggle_microphone()
            elif event.key == pygame.K_r and not is_speaking:
                reset_memory()
            elif event.key == pygame.K_ESCAPE:
                running = False

    # –ê–Ω–∏–º–∞—Ü–∏—è –º–∏–≥–∞–Ω–∏—è
    if not is_speaking and not mic_active and current_time > blush_until:
        if not is_blinking and current_time - last_blink > random.uniform(2.0, 4.0):
            is_blinking = True
            blink_start = current_time
            last_blink = current_time
        
        if is_blinking and current_time - blink_start > blink_duration:
            is_blinking = False

    # –ê–Ω–∏–º–∞—Ü–∏—è –∫–∏–≤–∞–Ω–∏—è –ø—Ä–∏ —Ä–µ—á–∏
    bob_offset = 0
    if is_speaking:
        bob_offset = math.sin((current_time - speech_start_time) * 1.5 * 2 * math.pi) * 10

    # –í—ã–±–æ—Ä –ª–∏—Ü–∞
    if current_time < blush_until:
        face = BLUSH_FACE
        face_color = BLUSH_COLOR
    elif is_speaking:
        face = SPEAKING_FACE
        face_color = ROBOT_COLOR
    elif mic_active:
        face = LISTENING_FACE
        face_color = LISTENING_COLOR
    elif is_blinking:
        face = BLINK_FACE
        face_color = TEXT_COLOR
    else:
        face = IDLE_FACE
        face_color = TEXT_COLOR

    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ (—á–∏—Å—Ç—ã–π –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å!)
    screen.fill(BACKGROUND)
    
    face_text = face_font.render(face, True, face_color)
    base_y = HEIGHT // 2 - 30
    draw_y = base_y + (bob_offset if is_speaking else 0)
    screen.blit(face_text, face_text.get_rect(center=(WIDTH // 2, draw_y)))
    
    # –°—Ç–∞—Ç—É—Å
    if is_speaking:
        status = "üí¨ Speaking... (mic muted)"
        status_color = ROBOT_COLOR
    elif mic_active:
        status = "üé§ Listening..."
        status_color = LISTENING_COLOR
    elif current_time < blush_until:
        status = "üò≥ *blushing*"
        status_color = BLUSH_COLOR
    else:
        status = "üí§ Say 'kitty' or press SPACE (R to reset)"
        status_color = IDLE_COLOR
    
    status_text = status_font.render(status, True, status_color)
    screen.blit(status_text, status_text.get_rect(center=(WIDTH // 2, HEIGHT - 80)))
    
    pygame.display.flip()
    clock.tick(60)

# –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
wake_word_active = False
stop_listening = True

if audio_stream:
    audio_stream.stop_stream()
    audio_stream.close()
if pyaudio_instance:
    pyaudio_instance.terminate()
if wake_stream:
    wake_stream.stop_stream()
    wake_stream.close()
if wake_pyaudio:
    wake_pyaudio.terminate()

print("\n\033[1;35m" + "="*60 + "\033[0m")
print_system("–ú–ò–ö–ê –ó–ê–í–ï–†–®–ò–õ–ê –†–ê–ë–û–¢–£. –ü–û–ö–ê-–ü–û–ö–ê! ^œâ^", "35")
print("\033[1;35m" + "="*60 + "\033[0m\n")
pygame.quit()
sys.exit()
